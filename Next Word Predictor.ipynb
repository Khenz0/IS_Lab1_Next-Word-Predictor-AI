{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab6f1e5d-54b2-4861-a838-254991ab6b38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import heapq\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8cdac11-c039-4bab-91c4-3e92e35a0ef4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load text data from a CSV file\n",
    "text_df = pd.read_csv(\"news.csv\")\n",
    "text = list(text_df.text.values)\n",
    "joined_text = \" \".join(text)\n",
    "\n",
    "# Save the joined text to a text file\n",
    "with open(\"joined_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(joined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b37da10-c72c-49a6-83b3-91ed9504689d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Take a partial portion of the text for tokenization\n",
    "partial_text = joined_text[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8a12caf-9d1e-4916-8554-7b102cf2abfa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize the partial text using a regular expression tokenizer\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b351bd43-00b3-4421-b572-b633849b382c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify unique tokens and create an index mapping\n",
    "unique_tokens = np.unique(tokens)\n",
    "unique_token_index = {token: index for index, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4581b8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016' '2020' '5' '60' 'a' 'abc' 'abcpolitics' 'abedin' 'about'\n",
      " 'aboutface' 'abuses' 'accused' 'accusing' 'act' 'ad' 'admits' 'ads'\n",
      " 'afraid' 'after' 'afternoon' 'against' 'age' 'agency' 'agents' 'ago'\n",
      " 'ahead' 'alive' 'all' 'allegations' 'allies' 'allowed' 'already' 'also'\n",
      " 'amendment' 'americans' 'an' 'and' 'announced' 'anthony' 'any' 'anywhere'\n",
      " 'apolitical' 'appearance' 'appeared' 'appearing' 'appeaser' 'approach'\n",
      " 'are' 'around' 'arrogant' 'article' 'as' 'asked' 'assault' 'assaulting'\n",
      " 'assaults' 'associates' 'assume' 'at' 'attack' 'attacked' 'attacking'\n",
      " 'away' 'awkward' 'awkwardly' 'back' 'backed' 'bad' 'badly' 'batch'\n",
      " 'bathroom' 'be' 'becoming' 'beds' 'been' 'before' 'behavior' 'behind'\n",
      " 'being' 'belief' 'believes' 'believing' 'better' 'between' 'bigger'\n",
      " 'bigotry' 'bizarre' 'boldly' 'born' 'boston' 'bragged' 'breathing'\n",
      " 'breeze' 'breezy' 'bribery' 'bring' 'bureau' 'buried' 'but' 'by' 'cable'\n",
      " 'calling' 'came' 'campaign' 'can' 'candidate' 'cards' 'career' 'careers'\n",
      " 'carville' 'center' 'chances' 'changed' 'charge' 'chilly' 'circulated'\n",
      " 'claim' 'claimed' 'claiming' 'classified' 'clearly' 'clinton' 'clintons'\n",
      " 'clintonworld' 'close' 'closing' 'cnn' 'co' 'collapsed' 'colleagues'\n",
      " 'column' 'com' 'coma' 'come' 'comey' 'comment' 'compared' 'computer'\n",
      " 'confident' 'conservative' 'conspiracies' 'conspiracy' 'continue'\n",
      " 'control' 'conviction' 'coordinating' 'corrected' 'corruption' 'could'\n",
      " 'couldn' 'countless' 'country' 'courage' 'course' 'cover' 'covert'\n",
      " 'cowardice' 'coy' 'cravenly' 'credibility' 'crime' 'criminal' 'cunning'\n",
      " 'currently' 'cycle' 'damaging' 'daniel' 'day' 'days' 'debate' 'decided'\n",
      " 'decides' 'declare' 'declared' 'declaring' 'defending' 'delicious'\n",
      " 'democratic' 'democrats' 'denial' 'deny' 'desperate' 'desperately'\n",
      " 'desperation' 'destroy' 'development' 'did' 'didn' 'digg' 'director'\n",
      " 'display' 'dnc' 'do' 'doj' 'don' 'done' 'dosed' 'down' 'during' 'edgar'\n",
      " 'editorial' 'either' 'elect' 'election' 'else' 'email' 'emailing'\n",
      " 'emails' 'endorsement' 'energy' 'enjoys' 'enough' 'entire' 'especially'\n",
      " 'establishment' 'even' 'ever' 'every' 'everyone' 'exactly' 'example'\n",
      " 'exist' 'existence' 'explanation' 'explanations' 'explosively' 'exposed'\n",
      " 'exposing' 'fairly' 'fbi' 'fear' 'federal' 'feigned' 'fellow' 'few'\n",
      " 'fight' 'fighting' 'figurehead' 'filled' 'film' 'final' 'finding' 'fire'\n",
      " 'fireworks' 'flailing' 'focused' 'focusing' 'followed' 'for' 'form'\n",
      " 'foundation' 'freedom' 'from' 'front' 'fundamental' 'futures' 'gasoline'\n",
      " 'gave' 'given' 'glancing' 'globe' 'go' 'going' 'gone' 'good' 'google'\n",
      " 'got' 'greenfield' 'hacks' 'had' 'happened' 'hard' 'harry' 'has' 'hatch'\n",
      " 'hates' 'have' 'he' 'head' 'headline' 'hell' 'her' 'here' 'hillary' 'him'\n",
      " 'himself' 'his' 'hit' 'home' 'hoover' 'hope' 'hospital' 'hour' 'house'\n",
      " 'how' 'however' 'https' 'hubris' 'huma' 'hurt' 'idea' 'if' 'illegal'\n",
      " 'illegality' 'impropriety' 'in' 'information' 'insane' 'insisted'\n",
      " 'instant' 'instead' 'interesting' 'intimidation' 'into' 'investigation'\n",
      " 'investigators' 'irritating' 'is' 'islam' 'isn' 'it' 'its' 'j' 'james'\n",
      " 'jobs' 'journalism' 'just' 'justified' 'keep' 'keeping' 'kgb' 'kind'\n",
      " 'knew' 'know' 'lambasting' 'lash' 'last' 'latest' 'lead' 'leadership'\n",
      " 'leave' 'led' 'left' 'letter' 'level' 'lie' 'lies' 'like' 'limp'\n",
      " 'linkedin' 'lit' 'lived' 'loaded' 'locked' 'lofty' 'long' 'longer' 'look'\n",
      " 'lot' 'loyalists' 'lunatic' 'lynch' 'made' 'major' 'make' 'making' 'man'\n",
      " 'manages' 'many' 'match' 'may' 'meant' 'media' 'mess' 'might' 'miles'\n",
      " 'misguided' 'mob' 'moment' 'months' 'moral' 'more' 'most' 'msnbc' 'much'\n",
      " 'mysterious' 'navigate' 'near' 'never' 'new' 'news' 'nice' 'no' 'nobody'\n",
      " 'nominee' 'nonsense' 'not' 'nothing' 'november' 'now' 'numerous' 'obama'\n",
      " 'of' 'off' 'often' 'old' 'on' 'once' 'one' 'only' 'operation' 'opponent'\n",
      " 'option' 'or' 'original' 'other' 'ought' 'out' 'outcome' 'outdone' 'over'\n",
      " 'own' 'panicked' 'paranoid' 'particularly' 'party' 'pass' 'patients'\n",
      " 'paul' 'payroll' 'people' 'personal' 'pic' 'picked' 'picking' 'pieces'\n",
      " 'pinterest' 'place' 'plan' 'playing' 'pocket' 'political' 'politics'\n",
      " 'poses' 'positive' 'possible' 'postured' 'power' 'practically'\n",
      " 'preemptive' 'preemptively' 'president' 'presidential' 'pretend'\n",
      " 'pretending' 'previously' 'principled' 'principles' 'print' 'pro'\n",
      " 'procedural' 'procedure' 'prominent' 'promising' 'protecting' 'proved'\n",
      " 'public' 'published' 'pure' 'push' 'putin' 'question' 'questions'\n",
      " 'quickly' 'radical' 'rally' 'ranks' 'rating' 're' 'react'\n",
      " 'realdonaldtrump' 'reality' 'really' 'reason' 'recalls' 'recover'\n",
      " 'reddit' 'refused' 'reid' 'relevance' 'relief' 'remembered' 'remind'\n",
      " 'replaced' 'republican' 'republicans' 'resignation' 'respected' 'respond'\n",
      " 'results' 'retired' 'reveal' 'revelation' 'reversed' 'review' 'ride'\n",
      " 'rigged' 'right' 'ringing' 'risk' 'rodham' 'role' 'running' 'ryan' 's'\n",
      " 'same' 'savage' 'says' 'scandal' 'scandals' 'scene' 'screwed' 'security'\n",
      " 'seemed' 'senator' 'senior' 'sent' 'server' 'setup' 'sexism' 'sexual'\n",
      " 'she' 'shillman' 'short' 'shove' 'shown' 'shrugged' 'sigh' 'slightest'\n",
      " 'smart' 'smell' 'smoke' 'sniveling' 'so' 'space' 'speaker' 'speakerryan'\n",
      " 'speaks' 'spectrum' 'spinelessness' 'spinmeisters' 'spouting' 'stage'\n",
      " 'staggering' 'stand' 'start' 'statement' 'states' 'stay' 'step' 'still'\n",
      " 'stored' 'stories' 'strange' 'strategy' 'stretch' 'struggle'\n",
      " 'stumbleupon' 'substance' 'such' 'sudden' 'suddenly' 'supporting'\n",
      " 'surprising' 'surreal' 'survival' 't' 'table' 'tak' 'taking' 'talked'\n",
      " 'tape' 'targeting' 'television' 'tells' 'tenth' 'than' 'that' 'the'\n",
      " 'their' 'them' 'then' 'there' 'they' 'thing' 'this' 'those' 'thought'\n",
      " 'threat' 'through' 'throughout' 'thrown' 'tied' 'time' 'times' 'to'\n",
      " 'today' 'too' 'train' 'trapped' 'trash' 'truly' 'trump' 'truths' 'try'\n",
      " 'trying' 'tumblr' 'turned' 'twitter' 'two' 'ugly' 'unapologetic'\n",
      " 'uncomfortable' 'under' 'underway' 'unfavorable' 'unite' 'united'\n",
      " 'unprecedented' 'unscathed' 'until' 'up' 'us' 'used' 'usual' 'utter'\n",
      " 'value' 'vast' 'very' 'victory' 'violating' 'violation' 'vladimir'\n",
      " 'volumes' 'vote' 'voted' 'vytt49yvoe' 'wake' 'waking' 'want' 'wants'\n",
      " 'war' 'warned' 'warning' 'was' 'watching' 'way' 'wcvscg4a5i' 'weathered'\n",
      " 'weeks' 'weiner' 'well' 'went' 'were' 'what' 'whatever' 'when' 'where'\n",
      " 'whether' 'which' 'while' 'who' 'whole' 'whose' 'why' 'wikipedia' 'will'\n",
      " 'wing' 'wiretaps' 'wisconsin' 'with' 'within' 'without' 'women' 'word'\n",
      " 'world' 'would' 'wouldn' 'wound' 'wreck' 'wreckage' 'writer' 'wrong'\n",
      " 'years' 'york' 'you' 'your' 'zero']\n"
     ]
    }
   ],
   "source": [
    "print(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b4e1458-225e-4f44-8fa2-f462aa6087bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the number of input words and initialize input and output data\n",
    "n_words = 10\n",
    "input_words = []\n",
    "next_word = []\n",
    "\n",
    "# Create input sequences and corresponding next words\n",
    "for i in range(len(tokens) - n_words):\n",
    "    input_words.append(tokens[i:i + n_words])\n",
    "    next_word.append(tokens[i + n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b4ce79-9fa7-41a2-a71b-c0a2134b16aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize binary matrices for input and output data\n",
    "X = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)  # for each sample, n input words and then a boolean for each possible next word\n",
    "y = np.zeros((len(next_word), len(unique_tokens)), dtype=bool)  # for each sample a boolean for each possible next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "758caffb-288e-4c16-878d-f969fde3d081",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Populate the binary matrices with one-hot encoded data\n",
    "for i, words in enumerate(input_words):\n",
    "    for j, word in enumerate(words):\n",
    "        X[i, j, unique_token_index[word]] = 1\n",
    "    y[i, unique_token_index[next_word[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89102ca3-b2fe-4a34-97c2-666164405ae8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88ad45b0-b793-429a-80f7-105b04e086c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 4s 62ms/step - loss: 6.2525 - accuracy: 0.0435\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 5.8538 - accuracy: 0.0618\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 5.8100 - accuracy: 0.0618\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 1s 62ms/step - loss: 5.7758 - accuracy: 0.0618\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 5.7427 - accuracy: 0.0618\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 5.6785 - accuracy: 0.0618\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 5.6226 - accuracy: 0.0624\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 5.5387 - accuracy: 0.0624\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 5.3962 - accuracy: 0.0664\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 1s 73ms/step - loss: 5.2261 - accuracy: 0.0818\n"
     ]
    }
   ],
   "source": [
    "# Define the optimizer and compile the model\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model and store the training history\n",
    "history = model.fit(X, y, batch_size=128, epochs=10, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1a5e92e-9d96-4691-bcfa-39a777c868ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Khenneth Malinao\\miniconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model and training history\n",
    "model.save(\"text_gen_model1.h5\")\n",
    "with open(\"history1.p\", \"wb\") as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "557f5ffa-e4d5-47fd-9f00-32b0b3e489ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the model / Start here if the model is already trained\n",
    "model = load_model(\"text_gen_model1.h5\")\n",
    "history = pickle.load(open(\"history1.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a1f478f-8e5e-4e82-bdc7-0b6620e5cadf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to predict the next word(s) given an input text\n",
    "def predict_next_word(input_text, n_best):\n",
    "    input_text = input_text.lower()\n",
    "    X = np.zeros((1, n_words, len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        X[0, i, unique_token_index[word]] = 1\n",
    "        \n",
    "    predictions = model.predict(X)[0]\n",
    "    return np.argpartition(predictions, -n_best)[-n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba954451-6237-4d21-9e9d-81e23bcd6fab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 725ms/step\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the predict_next_word function\n",
    "possible = predict_next_word(\"She will have to look into this thing and she\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfdef69f-618a-416c-a85c-51711adf86eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\n",
      "a\n",
      "to\n",
      "be\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "for idx in possible:\n",
    "    print(unique_tokens[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30d8a2cb-90cc-4698-8418-76ec38384450",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to generate text given an initial input and desired number of words\n",
    "def generate_text(input_text, n_words, creativity=3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(n_words):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
    "        try:\n",
    "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "        word_sequence.append(choice)\n",
    "        current += 1\n",
    "    return \" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c868ebb-be16-4d4f-84df-196d983e09c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'He must have one thing that I am into the bad justified struggle illegal else reversed bring television it of and be of that he s up a up of to of and it a act and and the him of a to war comey the of a of that fbi the hillary that her is but a fbi is hillary to fbi a any the of the but it hillary clinton of the unprecedented but and the to war on it fbi that of s foundation clinton that s of of hillary clinton clinton of and s but to t a him that of a war it and fbi'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate text using the generate_text function\n",
    "generate_text(\"He must have one thing that I am into the\", 100, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
